{
  "input": {
    "workflow": {
      "1": {
        "inputs": {
          "unet_name": "qwen_image_2512_fp8_e4m3fn_scaled_comfyui_4steps_v1.0.safetensors",
          "weight_dtype": "fp8_e4m3fn"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "Load Diffusion Model"
        }
      },
      "2": {
        "inputs": {
          "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
          "type": "lumina2",
          "device": "default"
        },
        "class_type": "CLIPLoader",
        "_meta": {
          "title": "Load CLIP"
        }
      },
      "3": {
        "inputs": {
          "vae_name": "qwen_image_vae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "Load VAE"
        }
      },
      "4": {
        "inputs": {
          "text": "blurry, low quality, distorted, deformed",
          "clip": ["2", 0]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Negative Prompt)"
        }
      },
      "6": {
        "inputs": {
          "text": "1girl, crop top, asian, bob cut, jeans, studio lighting, high quality",
          "clip": ["2", 0]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Positive Prompt)"
        }
      },
      "7": {
        "inputs": {
          "seed": 42,
          "steps": 4,
          "cfg": 1,
          "sampler_name": "euler",
          "scheduler": "normal",
          "denoise": 1,
          "model": ["1", 0],
          "positive": ["6", 0],
          "negative": ["4", 0],
          "latent_image": ["12", 0]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "12": {
        "inputs": {
          "width": 1024,
          "height": 1024,
          "batch_size": 1
        },
        "class_type": "EmptyLatentImage",
        "_meta": {
          "title": "Empty Latent Image"
        }
      },
      "25": {
        "inputs": {
          "samples": ["7", 0],
          "vae": ["3", 0]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAE Decode"
        }
      },
      "26": {
        "inputs": {
          "filename_prefix": "qwen_output",
          "images": ["25", 0]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "Save Image"
        }
      }
    }
  }
}
